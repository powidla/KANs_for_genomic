{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWeDk-z75g4m"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "from collections import Counter, OrderedDict\n",
        "from pathlib import Path\n",
        "from typing import ClassVar, Iterator, Sequence\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler, Subset\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import OrderedDict\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, matthews_corrcoef"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data flipon prep"
      ],
      "metadata": {
        "id": "utgYOOULWHuh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oY6t41gN1W1a"
      },
      "outputs": [],
      "source": [
        "shin = pd.read_csv(\"/content/Shin500_kan_dataset.csv\")\n",
        "endo = pd.read_csv(\"/content/Endoquad_kan_dataset.csv\")\n",
        "hdna = pd.read_csv(\"/content/HDNA500_kan_dataset.csv\")\n",
        "kou = pd.read_csv(\"/content/Kou500_kan_dataset.csv\")\n",
        "g4chip = pd.read_csv(\"/content/kan_g4_chip.csv\")\n",
        "g4cut = pd.read_csv(\"/content/kan_g4_cut.csv\")\n",
        "g4seq = pd.read_csv(\"/content/kan_g4_seq.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = hdna"
      ],
      "metadata": {
        "id": "FitQ_XiuW3ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[df['split'] == 'train']\n",
        "df_test = df[df['split'] == 'test']"
      ],
      "metadata": {
        "id": "U3P4ZLkrW5Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPQHuSAz3mAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c1f082-91e6-4535-b6a5-5ed4151e23d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(df_train[\"sequence\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "pxtIVVhHPeDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U0ZTsFS2Tk5"
      },
      "outputs": [],
      "source": [
        "encoding_map = {\n",
        "    \"A\": [1, 0, 0, 0],\n",
        "    \"T\": [0, 1, 0, 0],\n",
        "    \"C\": [0, 0, 1, 0],\n",
        "    \"G\": [0, 0, 0, 1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmkZzsaX2WoJ"
      },
      "outputs": [],
      "source": [
        "def encode_sequence(sequence):\n",
        "    encoded_seq = [encoding_map[base] for base in sequence if base in encoding_map]\n",
        "    return torch.tensor(encoded_seq, dtype=torch.float).t()\n",
        "\n",
        "def pad_sequences(sequences, target_length):\n",
        "    padded_sequences = []\n",
        "    for seq in sequences:\n",
        "        seq_len = seq.size(1)\n",
        "        if seq_len < target_length:\n",
        "            left_padding = (target_length - seq_len) // 2\n",
        "            right_padding = target_length - seq_len - left_padding\n",
        "            padded_seq = torch.nn.functional.pad(seq, (left_padding, right_padding))\n",
        "        else:\n",
        "            padded_seq = seq[:, :target_length]\n",
        "        padded_sequences.append(padded_seq)\n",
        "    return torch.stack(padded_sequences)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sequences, labels = zip(*batch)\n",
        "    sequence_lengths = [seq.size(1) for seq in sequences]\n",
        "    target_length = int(np.median(sequence_lengths))\n",
        "    padded_sequences = pad_sequences(sequences, target_length)\n",
        "    labels = torch.stack(labels)\n",
        "    return padded_sequences, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UucCNYDD1_Az"
      },
      "outputs": [],
      "source": [
        "class DNASequencesDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "        self.data = self.data[~self.data['sequence'].str.contains('N')].reset_index(drop=True)\n",
        "        self.encoded_sequences = [encode_sequence(seq) for seq in self.data['sequence']]\n",
        "        self.labels = torch.tensor(self.data['label'].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_sequences[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiOt5SnM2TB-"
      },
      "outputs": [],
      "source": [
        "train_dataset = DNASequencesDataset(df_train)\n",
        "test_dataset = DNASequencesDataset(df_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "I1wcoXJDNvQQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI0xJvw1SnDm"
      },
      "source": [
        "KAN Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTu2V80lvv6t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.size(-1) == self.in_features\n",
        "        original_shape = x.shape\n",
        "        x = x.reshape(-1, self.in_features)\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=True):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrkFFjPB5VkK"
      },
      "outputs": [],
      "source": [
        "class Bilinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified Bilinear layer that uses a single Linear layer for pairwise interaction.\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, out=None, bias=False):\n",
        "        super().__init__()\n",
        "        if out is None:\n",
        "            out = n\n",
        "        # self.fc = nn.Linear(n, out, bias=bias)\n",
        "        self.fc = KANLinear(n, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input if necessary\n",
        "        return self.fc(x)\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified Squeeze-and-Excite layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inp : int\n",
        "        Middle layer size.\n",
        "    oup : int\n",
        "        Input and output size.\n",
        "    reduction : int, optional\n",
        "        Reduction parameter. Default is 4.\n",
        "    \"\"\"\n",
        "    def __init__(self, inp, oup, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            KANLinear(oup, inp // reduction),\n",
        "            # nn.Linear(oup, inp // reduction, bias=False),\n",
        "            # nn.SiLU(),\n",
        "            KANLinear(inp // reduction, oup),\n",
        "            # nn.Linear(inp // reduction, oup, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _ = x.size()\n",
        "        y = x.view(b, c, -1).mean(dim=2)\n",
        "        y = self.fc(y).view(b, c, 1)\n",
        "        return x * y\n",
        "\n",
        "# Main SeqNN model\n",
        "class SeqNN(nn.Module):\n",
        "    \"\"\"\n",
        "    LegNet neural network for binary classification.\n",
        "    \"\"\"\n",
        "    __constants__ = ('resize_factor')\n",
        "\n",
        "    def __init__(self,\n",
        "                seqsize,\n",
        "                use_single_channel,\n",
        "                use_reverse_channel,\n",
        "                use_multisubstate_channel,\n",
        "                block_sizes=[256, 256, 128, 128, 64, 64, 32, 32],\n",
        "                ks=5,\n",
        "                resize_factor=4,\n",
        "                activation=nn.SiLU,\n",
        "                filter_per_group=2,\n",
        "                se_reduction=4,\n",
        "                final_ch=1,\n",
        "                bn_momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.block_sizes = block_sizes\n",
        "        self.resize_factor = resize_factor\n",
        "        self.se_reduction = se_reduction\n",
        "        self.seqsize = seqsize\n",
        "        self.use_single_channel = use_single_channel\n",
        "        self.use_reverse_channel = use_reverse_channel\n",
        "        self.use_multisubstate_channel = use_multisubstate_channel\n",
        "        self.final_ch = final_ch\n",
        "        self.bn_momentum = bn_momentum\n",
        "        seqextblocks = OrderedDict()\n",
        "\n",
        "        in_channels_first_block = 4\n",
        "        if self.use_single_channel:\n",
        "            in_channels_first_block += 1\n",
        "        if self.use_reverse_channel:\n",
        "            in_channels_first_block += 1\n",
        "        if self.use_multisubstate_channel:\n",
        "            in_channels_first_block += 1\n",
        "\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=in_channels_first_block,\n",
        "                out_channels=block_sizes[0],\n",
        "                kernel_size=ks,\n",
        "                padding='same',\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm1d(block_sizes[0], momentum=self.bn_momentum),\n",
        "            activation()\n",
        "        )\n",
        "        seqextblocks['blc0'] = block\n",
        "\n",
        "        # Building remaining blocks\n",
        "        for ind, (prev_sz, sz) in enumerate(zip(block_sizes[:-1], block_sizes[1:])):\n",
        "            block = nn.Sequential(\n",
        "                nn.Conv1d(prev_sz, sz * self.resize_factor, kernel_size=1, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "\n",
        "                nn.Conv1d(sz * self.resize_factor, sz * self.resize_factor, kernel_size=ks,\n",
        "                          groups=sz * self.resize_factor // filter_per_group, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "\n",
        "                SELayer(prev_sz, sz * self.resize_factor, reduction=self.se_reduction),\n",
        "\n",
        "                nn.Conv1d(sz * self.resize_factor, prev_sz, kernel_size=1, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(prev_sz, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "            )\n",
        "            seqextblocks[f'inv_res_blc{ind}'] = block\n",
        "\n",
        "            resize_block = nn.Sequential(\n",
        "                nn.Conv1d(2 * prev_sz, sz, kernel_size=ks, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz, momentum=self.bn_momentum),\n",
        "                activation()\n",
        "            )\n",
        "            seqextblocks[f'resize_blc{ind}'] = resize_block\n",
        "\n",
        "        self.seqextractor = nn.ModuleDict(seqextblocks)\n",
        "\n",
        "        self.mapper = nn.Sequential(\n",
        "            nn.Conv1d(block_sizes[-1], self.final_ch, kernel_size=1, padding='same'),\n",
        "            activation()\n",
        "        )\n",
        "\n",
        "        self.register_buffer('bins', torch.arange(start=0, end=self.final_ch, step=1, requires_grad=False))\n",
        "\n",
        "    def feature_extractor(self, x):\n",
        "        x = self.seqextractor['blc0'](x)\n",
        "        for i in range(len(self.block_sizes) - 1):\n",
        "            x = torch.cat([x, self.seqextractor[f'inv_res_blc{i}'](x)], dim=1)\n",
        "            x = self.seqextractor[f'resize_blc{i}'](x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.feature_extractor(x)\n",
        "        x = self.mapper(f)\n",
        "        x = F.adaptive_avg_pool1d(x, 1)\n",
        "        x = x.squeeze(2)\n",
        "        prob = torch.sigmoid(x).squeeze(1)\n",
        "\n",
        "        return prob\n",
        "        # logprobs = F.log_softmax(x, dim=1)\n",
        "\n",
        "        # # Soft-argmax operation (optional)\n",
        "        # x = F.softmax(x, dim=1)\n",
        "        # score = (x * self.bins).sum(dim=1)\n",
        "\n",
        "        # return logprobs, score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KAN Conv"
      ],
      "metadata": {
        "id": "583UDEC_OIBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Util\n",
        "def add_padding_1d(array: np.ndarray, padding: int) -> np.ndarray:\n",
        "    \"\"\"Adds padding to a 1D array.\"\"\"\n",
        "    n = array.shape[0]\n",
        "    padded_array = np.zeros(n + 2 * padding)\n",
        "    padded_array[padding: n + padding] = array\n",
        "    return padded_array\n",
        "\n",
        "\n",
        "def calc_out_dims_1d(array, kernel_size, stride, dilation, padding):\n",
        "    \"\"\"Calculate output dimensions for 1D convolution.\"\"\"\n",
        "    batch_size, n_channels, n = matrix.shape\n",
        "    out_size = np.floor((n + 2 * padding - kernel_size - (kernel_size - 1) * (dilation - 1)) / stride).astype(int) + 1\n",
        "    return out_size, batch_size, n_channels\n",
        "\n",
        "\n",
        "def multiple_convs_kan_conv1d(array,\n",
        "                               kernels,\n",
        "                               kernel_size,\n",
        "                               out_channels,\n",
        "                               stride=1,\n",
        "                               dilation=1,\n",
        "                               padding=0,\n",
        "                               device=\"cuda\") -> torch.Tensor:\n",
        "    \"\"\"Performs a 1D convolution with multiple kernels on the input array using specified stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        array (torch.Tensor): 1D tensor of shape (batch_size, channels, length).\n",
        "        kernels (list): List of kernel functions to be applied.\n",
        "        kernel_size (int): Size of the 1D kernel.\n",
        "        out_channels (int): Number of output channels.\n",
        "        stride (int): Stride along the length of the array. Default is 1.\n",
        "        dilation (int): Dilation rate along the length of the array. Default is 1.\n",
        "        padding (int): Number of elements to pad on each side. Default is 0.\n",
        "        device (str): Device to perform calculations on. Default is \"cuda\".\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Feature map after convolution with shape (batch_size, out_channels, length_out).\n",
        "    \"\"\"\n",
        "    length_out, batch_size = calc_out_dims_1d(array, kernel_size, stride, dilation, padding)\n",
        "    n_convs = len(kernels)\n",
        "\n",
        "    array_out = torch.zeros((batch_size, out_channels, length_out)).to(device)\n",
        "\n",
        "    array = F.pad(array, (padding, padding), mode='constant', value=0)\n",
        "    conv_groups = array.unfold(2, kernel_size, stride)\n",
        "    conv_groups = conv_groups.contiguous()\n",
        "\n",
        "    kern_per_out = len(kernels) // out_channels\n",
        "\n",
        "    for c_out in range(out_channels):\n",
        "        out_channel_accum = torch.zeros((batch_size, length_out), device=device)\n",
        "\n",
        "        for k_idx in range(kern_per_out):\n",
        "            kernel = kernels[c_out * kern_per_out + k_idx]\n",
        "            conv_result = kernel(conv_groups.view(-1, 1, kernel_size))\n",
        "            out_channel_accum += conv_result.view(batch_size, length_out)\n",
        "\n",
        "        array_out[:, c_out, :] = out_channel_accum\n",
        "\n",
        "    return array_out"
      ],
      "metadata": {
        "id": "6_mZ4DU-OJ1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kan_conv1d(matrix: torch.Tensor,\n",
        "               kernel,\n",
        "               kernel_size: int,\n",
        "               stride: int = 1,\n",
        "               dilation: int = 1,\n",
        "               padding: int = 0,\n",
        "               device: str = \"cpu\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Performs a 1D convolution with the given kernel over a 1D matrix using the defined stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): 3D tensor (batch_size, channels, width) to be convolved.\n",
        "        kernel (function): Kernel function to apply on the 1D patches of the matrix.\n",
        "        kernel_size (int): Size of the kernel (assumed to be square).\n",
        "        stride (int, optional): Stride along the width axis. Defaults to 1.\n",
        "        dilation (int, optional): Dilation along the width axis. Defaults to 1.\n",
        "        padding (int, optional): Padding along the width axis. Defaults to 0.\n",
        "        device (str): Device to perform the operation on (e.g., \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 1D Feature map after convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, n_channels, width_in = matrix.shape\n",
        "    width_out = ((width_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride) + 1\n",
        "    matrix_out = torch.zeros((batch_size, n_channels, width_out), device=device)\n",
        "\n",
        "    matrix_padded = torch.nn.functional.pad(matrix, (padding, padding))\n",
        "\n",
        "    for i in range(width_out):\n",
        "\n",
        "        start = i * stride\n",
        "        end = start + kernel_size * dilation\n",
        "        patch = matrix_padded[:, :, start:end:dilation]\n",
        "\n",
        "        matrix_out[:, :, i] = kernel.forward(patch).squeeze(-1)\n",
        "\n",
        "    return matrix_out"
      ],
      "metadata": {
        "id": "qFsgL3gAOJ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=0, dilation=1, device=\"cuda\"):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.device = device\n",
        "        self.convs = torch.nn.ModuleList([KAN_Convolution_1D(kernel_size, stride, padding, dilation, device) for _ in range(in_channels * out_channels)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return torch.cat([conv(x[:, i, :].unsqueeze(1)) for i, conv in enumerate(self.convs)], dim=1)"
      ],
      "metadata": {
        "id": "uTYnlRbuOafR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int = 1,\n",
        "            out_channels: int = 1,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 5,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1],\n",
        "            device: str = \"cpu\"\n",
        "        ):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(in_channels * out_channels):\n",
        "            self.convs.append(\n",
        "                KAN_Convolution_1D(\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        batch_size, in_channels, length = x.shape\n",
        "        output_length = (length + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1) // self.stride + 1\n",
        "        output = torch.zeros((batch_size, self.out_channels, output_length), device=x.device)\n",
        "\n",
        "\n",
        "        for i in range(self.out_channels):\n",
        "            output_accum = torch.zeros((batch_size, output_length), device=x.device)\n",
        "            for j in range(self.in_channels):\n",
        "                kernel_idx = i * self.in_channels + j\n",
        "                conv_result = self.convs[kernel_idx].forward(x[:, j, :].unsqueeze(1))\n",
        "                output_accum += conv_result.squeeze(1)  # Squeeze\n",
        "            output[:, i, :] = output_accum  # A to output channel\n",
        "\n",
        "        return output\n",
        "\n",
        "class KAN_Convolution_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 50,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1]\n",
        "        ):\n",
        "        super(KAN_Convolution_1D, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.conv = KANLinear(\n",
        "            in_features = kernel_size,\n",
        "            out_features = 1,\n",
        "            grid_size=grid_size,\n",
        "            spline_order=spline_order,\n",
        "            scale_noise=scale_noise,\n",
        "            scale_base=scale_base,\n",
        "            scale_spline=scale_spline,\n",
        "            base_activation=base_activation,\n",
        "            grid_eps=grid_eps,\n",
        "            grid_range=grid_range\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        self.device = x.device\n",
        "        return kan_conv1d(x, self.conv, self.kernel_size,self.stride, self.dilation, self.padding, self.device)"
      ],
      "metadata": {
        "id": "RpaqZpyKOrDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example with changed mapper"
      ],
      "metadata": {
        "id": "Mq70bw4wO6XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class SeqNN(nn.Module):\n",
        "#     \"\"\"\n",
        "#     SeqNN neural network for binary classification with modified mapper using KAN_Convolutional_Layer_1D.\n",
        "#     \"\"\"\n",
        "#     def __init__(self,\n",
        "#                  seqsize,\n",
        "#                  use_single_channel,\n",
        "#                  use_reverse_channel,\n",
        "#                  use_multisubstate_channel,\n",
        "#                  block_sizes=[256, 256, 128, 128, 64, 64, 32, 32],\n",
        "#                  ks=5,\n",
        "#                  resize_factor=4,\n",
        "#                  activation=nn.SiLU,\n",
        "#                  filter_per_group=2,\n",
        "#                  se_reduction=4,\n",
        "#                  final_ch=1,\n",
        "#                  bn_momentum=0.1):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.block_sizes = block_sizes\n",
        "#         self.resize_factor = resize_factor\n",
        "#         self.se_reduction = se_reduction\n",
        "#         self.seqsize = seqsize\n",
        "#         self.use_single_channel = use_single_channel\n",
        "#         self.use_reverse_channel = use_reverse_channel\n",
        "#         self.use_multisubstate_channel = use_multisubstate_channel\n",
        "#         self.final_ch = final_ch\n",
        "#         self.bn_momentum = bn_momentum\n",
        "\n",
        "#         seqextblocks = OrderedDict()\n",
        "#         in_channels_first_block = 4  # 4 channels for A, T, C, G\n",
        "#         if self.use_single_channel:\n",
        "#             in_channels_first_block += 1\n",
        "#         if self.use_reverse_channel:\n",
        "#             in_channels_first_block += 1\n",
        "#         if self.use_multisubstate_channel:\n",
        "#             in_channels_first_block += 1\n",
        "\n",
        "#         # First layer\n",
        "#         block = nn.Sequential(\n",
        "#             nn.Conv1d(\n",
        "#                 in_channels=in_channels_first_block,\n",
        "#                 out_channels=block_sizes[0],\n",
        "#                 kernel_size=ks,\n",
        "#                 padding='same',\n",
        "#                 bias=False\n",
        "#             ),\n",
        "#             nn.BatchNorm1d(block_sizes[0], momentum=self.bn_momentum),\n",
        "#             activation()\n",
        "#         )\n",
        "#         seqextblocks['blc0'] = block\n",
        "\n",
        "#         # Building remaining blocks\n",
        "#         for ind, (prev_sz, sz) in enumerate(zip(block_sizes[:-1], block_sizes[1:])):\n",
        "#             block = nn.Sequential(\n",
        "#                 nn.Conv1d(prev_sz, sz * self.resize_factor, kernel_size=1, padding='same', bias=False),\n",
        "#                 nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "#                 activation(),\n",
        "\n",
        "#                 nn.Conv1d(sz * self.resize_factor, sz * self.resize_factor, kernel_size=ks,\n",
        "#                           groups=sz * self.resize_factor // filter_per_group, padding='same', bias=False),\n",
        "#                 nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "#                 activation(),\n",
        "\n",
        "#                 SELayer(prev_sz, sz * self.resize_factor, reduction=self.se_reduction),\n",
        "\n",
        "#                 nn.Conv1d(sz * self.resize_factor, prev_sz, kernel_size=1, padding='same', bias=False),\n",
        "#                 nn.BatchNorm1d(prev_sz, momentum=self.bn_momentum),\n",
        "#                 activation(),\n",
        "#             )\n",
        "#             seqextblocks[f'inv_res_blc{ind}'] = block\n",
        "\n",
        "#             resize_block = nn.Sequential(\n",
        "#                 nn.Conv1d(2 * prev_sz, sz, kernel_size=ks, padding='same', bias=False),\n",
        "#                 nn.BatchNorm1d(sz, momentum=self.bn_momentum),\n",
        "#                 activation()\n",
        "#             )\n",
        "#             seqextblocks[f'resize_blc{ind}'] = resize_block\n",
        "\n",
        "#         self.seqextractor = nn.ModuleDict(seqextblocks)\n",
        "\n",
        "#         self.mapper = nn.Sequential(\n",
        "#             KAN_Convolutional_Layer_1D(\n",
        "#                 in_channels=block_sizes[-1],\n",
        "#                 out_channels=self.final_ch,\n",
        "#                 kernel_size=1,\n",
        "#                 padding=0,\n",
        "#                 device=\"cuda\"\n",
        "#             ),\n",
        "#             activation()\n",
        "#         )\n",
        "\n",
        "#         self.register_buffer('bins', torch.arange(start=0, end=self.final_ch, step=1, requires_grad=False))\n",
        "\n",
        "#     def feature_extractor(self, x):\n",
        "#         x = self.seqextractor['blc0'](x)\n",
        "#         for i in range(len(self.block_sizes) - 1):\n",
        "#             x = torch.cat([x, self.seqextractor[f'inv_res_blc{i}'](x)], dim=1)\n",
        "#             x = self.seqextractor[f'resize_blc{i}'](x)\n",
        "#         return x\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         f = self.feature_extractor(x)\n",
        "#         x = self.mapper(f)\n",
        "#         x = F.adaptive_avg_pool1d(x, 1)\n",
        "#         x = x.squeeze(2)\n",
        "#         prob = torch.sigmoid(x).squeeze(1)\n",
        "\n",
        "#         return prob"
      ],
      "metadata": {
        "id": "Vz-gXm0iO3ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzqUJs3V5Sib"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNgMwQp57y-x"
      },
      "outputs": [],
      "source": [
        "model = SeqNN(\n",
        "    seqsize=512,\n",
        "    use_single_channel=False,\n",
        "    use_reverse_channel=False,\n",
        "    use_multisubstate_channel=False,\n",
        "    final_ch=1\n",
        ")\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.005)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayyNG-mq8Ard",
        "outputId": "62bb7da5-f9be-4478-b723-bc59b1f04697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeqNN(\n",
              "  (seqextractor): ModuleDict(\n",
              "    (blc0): Sequential(\n",
              "      (0): Conv1d(4, 256, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc0): Sequential(\n",
              "      (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=same, groups=512, bias=False)\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc0): Sequential(\n",
              "      (0): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc1): Sequential(\n",
              "      (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=same, groups=256, bias=False)\n",
              "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(512, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc1): Sequential(\n",
              "      (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc2): Sequential(\n",
              "      (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=same, groups=256, bias=False)\n",
              "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(512, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc2): Sequential(\n",
              "      (0): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc3): Sequential(\n",
              "      (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=same, groups=128, bias=False)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc3): Sequential(\n",
              "      (0): Conv1d(256, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc4): Sequential(\n",
              "      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=same, groups=128, bias=False)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc4): Sequential(\n",
              "      (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc5): Sequential(\n",
              "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, groups=64, bias=False)\n",
              "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(128, 64, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc5): Sequential(\n",
              "      (0): Conv1d(128, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc6): Sequential(\n",
              "      (0): Conv1d(32, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, groups=64, bias=False)\n",
              "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (1): KANLinear(\n",
              "            (base_activation): SiLU()\n",
              "          )\n",
              "          (2): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(128, 32, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc6): Sequential(\n",
              "      (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "  )\n",
              "  (mapper): Sequential(\n",
              "    (0): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
              "    (1): SiLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB0Z02CDwoLd",
        "outputId": "06185e1e-463f-49de-d8b2-faf0d7f105b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 4990177\n"
          ]
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi1oWMvj7S7p"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for sequences, labels in loader:\n",
        "        sequences, labels = sequences.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        probs = model(sequences)\n",
        "        loss = criterion(probs, labels.float())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * sequences.size(0)\n",
        "        all_preds.extend(probs.detach().cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "\n",
        "    all_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, accuracy, f1, auc, precision, recall, mcc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    eval_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "\n",
        "            probs = model(sequences)\n",
        "            loss = criterion(probs, labels.float())\n",
        "            eval_loss += loss.item() * sequences.size(0)\n",
        "\n",
        "            all_preds.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = eval_loss / len(loader.dataset)\n",
        "\n",
        "    all_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, accuracy, f1, auc, precision, recall, mcc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shin"
      ],
      "metadata": {
        "id": "eeiHCbtvZVWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 7\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSB1G04xZDnG",
        "outputId": "7fd0f05d-b97a-492e-a1ec-0e30968419d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "Train - Loss: 0.5691, Acc: 0.7962, F1: 0.8223, AUC: 0.7959, Precision: 0.7299, Recall: 0.9414, MCC: 0.6188\n",
            "Val   - Loss: 0.6939, Acc: 0.5034, F1: 0.0000, AUC: 0.5000, Precision: 0.0000, Recall: 0.0000, MCC: 0.0000\n",
            "Epoch 2/7\n",
            "Train - Loss: 0.4617, Acc: 0.9206, F1: 0.9246, AUC: 0.9205, Precision: 0.8812, Recall: 0.9724, MCC: 0.8456\n",
            "Val   - Loss: 0.4923, Acc: 0.7034, F1: 0.7701, AUC: 0.7055, Precision: 0.6261, Recall: 1.0000, MCC: 0.5072\n",
            "Epoch 3/7\n",
            "Train - Loss: 0.3911, Acc: 0.9741, F1: 0.9741, AUC: 0.9741, Precision: 0.9758, Recall: 0.9724, MCC: 0.9482\n",
            "Val   - Loss: 0.3671, Acc: 1.0000, F1: 1.0000, AUC: 1.0000, Precision: 1.0000, Recall: 1.0000, MCC: 1.0000\n",
            "Epoch 4/7\n",
            "Train - Loss: 0.3751, Acc: 0.9793, F1: 0.9792, AUC: 0.9793, Precision: 0.9826, Recall: 0.9759, MCC: 0.9586\n",
            "Val   - Loss: 0.3656, Acc: 0.9862, F1: 0.9863, AUC: 0.9863, Precision: 0.9730, Recall: 1.0000, MCC: 0.9728\n",
            "Epoch 5/7\n",
            "Train - Loss: 0.3567, Acc: 0.9827, F1: 0.9829, AUC: 0.9827, Precision: 0.9762, Recall: 0.9897, MCC: 0.9655\n",
            "Val   - Loss: 0.3499, Acc: 0.9862, F1: 0.9859, AUC: 0.9861, Precision: 1.0000, Recall: 0.9722, MCC: 0.9728\n",
            "Epoch 6/7\n",
            "Train - Loss: 0.3501, Acc: 0.9793, F1: 0.9792, AUC: 0.9793, Precision: 0.9826, Recall: 0.9759, MCC: 0.9586\n",
            "Val   - Loss: 0.3212, Acc: 1.0000, F1: 1.0000, AUC: 1.0000, Precision: 1.0000, Recall: 1.0000, MCC: 1.0000\n",
            "Epoch 7/7\n",
            "Train - Loss: 0.3550, Acc: 0.9689, F1: 0.9693, AUC: 0.9689, Precision: 0.9595, Recall: 0.9793, MCC: 0.9380\n",
            "Val   - Loss: 0.4907, Acc: 0.8345, F1: 0.8000, AUC: 0.8333, Precision: 1.0000, Recall: 0.6667, MCC: 0.7083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kou"
      ],
      "metadata": {
        "id": "asz4hkRXZko1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "eu-QGtIoZkwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HDNA"
      ],
      "metadata": {
        "id": "yTdFR2d_wn9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "stMQQu-3woGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Endo"
      ],
      "metadata": {
        "id": "AtrAUMztwqGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "Y_oHx-QSwqNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "g4chip"
      ],
      "metadata": {
        "id": "nJ6wmXuDdWUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "mAqa3U99dWeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "g4cut"
      ],
      "metadata": {
        "id": "9djnVxYIdWla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "h0GSnp8bdWqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "g4seq"
      ],
      "metadata": {
        "id": "9d1BXWktdWv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")"
      ],
      "metadata": {
        "id": "X0lGZ5uodW0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}